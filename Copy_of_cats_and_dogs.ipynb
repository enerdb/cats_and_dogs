{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cats_and_dogs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTwq7HXnmYdm7mJsOwHgBU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enerdb/cats_and_dogs/blob/main/Copy_of_cats_and_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg9zSbFoXTlf",
        "outputId": "558bed5c-ab1b-4fb9-8583-6b7a4240199b"
      },
      "source": [
        "!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-20 18:01:08--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.193.128, 172.217.204.128, 172.217.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.193.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘cats_and_dogs_filtered.zip’\n",
            "\n",
            "cats_and_dogs_filte 100%[===================>]  65.43M   150MB/s    in 0.4s    \n",
            "\n",
            "2021-09-20 18:01:09 (150 MB/s) - ‘cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvFaz8D7WPO1"
      },
      "source": [
        "!unzip cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu-_PHZTXXeX"
      },
      "source": [
        "!rm -rf cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50jDe6U4Yjsm"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1zqODPZYnEX"
      },
      "source": [
        "# os auxilia em tarefes no Sistema operacional\n",
        "import os\n",
        "# plotar imagens\n",
        "import matplotlib.pyplot as plt\n",
        "# implementação do modelo\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWBThF5xYtuN",
        "outputId": "d4452bb8-bc11-45da-9901-55299fc6daff"
      },
      "source": [
        "dataset_dir = os.path.join(os.getcwd(), 'cats_and_dogs_filtered')\n",
        "\n",
        "dataset_train_dir = os.path.join(dataset_dir, 'train')\n",
        "dataset_train_cats_len = len(os.listdir(os.path.join(dataset_train_dir, 'cats')))\n",
        "dataset_train_dogs_len = len(os.listdir(os.path.join(dataset_train_dir, 'dogs')))\n",
        "\n",
        "dataset_validation_dir = os.path.join(dataset_dir, 'validation')\n",
        "dataset_validation_cats_len = len(os.listdir(os.path.join(dataset_validation_dir, 'cats')))\n",
        "dataset_validation_dogs_len = len(os.listdir(os.path.join(dataset_validation_dir, 'dogs')))\n",
        "\n",
        "print('Train Cats: %s' % dataset_train_cats_len)\n",
        "print('Train Dogs: %s' % dataset_train_dogs_len)\n",
        "print('Validation Cats: %s' % dataset_validation_cats_len)\n",
        "print('Validation Dogs: %s' % dataset_validation_dogs_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Cats: 1000\n",
            "Train Dogs: 1000\n",
            "Validation Cats: 500\n",
            "Validation Dogs: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GnIsKpyc-Rn"
      },
      "source": [
        "Preprocessing:\n",
        "\n",
        "Size: 160x160 (scaling)\n",
        "Value by color 0-255 RGB\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtKl7ICBdA-_"
      },
      "source": [
        "image_width = 160\n",
        "image_height = 160\n",
        "image_color_channel = 3\n",
        "image_color_channel_size = 255\n",
        "image_size = (image_width, image_height)\n",
        "image_shape = image_size + (image_color_channel, )\n",
        "\n",
        "# number of features used per batch\n",
        "batch_size = 32 \n",
        "# number of times the dataset will participate n training\n",
        "epochs = 20\n",
        "# learning rate\n",
        "learning_rate = 0.0001\n",
        "\n",
        "class_names = ['cat', 'dog']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VllfpfI9eY4F",
        "outputId": "3587b3d9-4a8a-4c2e-9181-d70f71f66992"
      },
      "source": [
        "dataset_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_train_dir,\n",
        "    image_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrpfiOVQe6DZ",
        "outputId": "71a756e6-1773-46fb-8542-14eff5300809"
      },
      "source": [
        "dataset_validation_pre = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_validation_dir,\n",
        "    image_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHDceNF3fIiQ",
        "outputId": "ef8ae833-852d-4172-cf4c-f120b8e13f50"
      },
      "source": [
        "dataset_validation_cardinality = tf.data.experimental.cardinality(dataset_validation_pre)\n",
        "dataset_validation_batches = dataset_validation_cardinality // 5\n",
        "\n",
        "dataset_test = dataset_validation_pre.take(dataset_validation_batches)\n",
        "dataset_validation = dataset_validation_pre.skip(dataset_validation_batches)\n",
        "\n",
        "print('Validation Dataset Cardinality: %d' % tf.data.experimental.cardinality(dataset_validation))\n",
        "print('Test Dataset Cardinality: %d' % tf.data.experimental.cardinality(dataset_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Dataset Cardinality: 26\n",
            "Test Dataset Cardinality: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5FGG2iUoPDl"
      },
      "source": [
        "# Function to display images of a dataset\n",
        "\n",
        "def plot_dataset(dataset):\n",
        "\n",
        "  plt.gcf().clear()\n",
        "  plt.figure(figsize = (15,15))\n",
        "\n",
        "  for features, labels in dataset.take(1):\n",
        "      for i in range(9):\n",
        "    \n",
        "          plt.subplot(3, 3, i+1)\n",
        "          plt.axis('off')\n",
        "\n",
        "          plt.imshow(features[i].numpy().astype('uint8'))\n",
        "          plt.title(class_names[labels[i]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1eQe66yo3P8",
        "outputId": "d36290d1-a959-44c1-fa08-131c5463585b"
      },
      "source": [
        "# model training\n",
        "\n",
        "# Sequential - each layer is applied after the other\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Rescaling (160, 160, 3), values from 0 to 1\n",
        "    tf.keras.layers.experimental.preprocessing.Rescaling(\n",
        "        1. /image_color_channel_size,\n",
        "        input_shape = image_shape\n",
        "    ),\n",
        "    # Convolutional Layer, Kernel 3x3 passed 16x\n",
        "    # padding = same - zeros around feature\n",
        "    # activation function = relu - zero if negative\n",
        "    tf.keras.layers.Conv2D(16, 3, padding = 'same', activation = 'relu'),\n",
        "    # MaxPooling consolidates the activation map from a Convolution layer\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    # Flattens the output\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
        "])\n",
        "\n",
        "#\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling (Rescaling)        (None, 160, 160, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 160, 160, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 80, 80, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 80, 80, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 40, 40, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 40, 40, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 20, 20, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25600)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               3276928   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 3,300,641\n",
            "Trainable params: 3,300,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cQ3ZxmDxFFs",
        "outputId": "445a3ec6-1af0-4663-eb45-704473cd7994"
      },
      "source": [
        "history = model.fit(\n",
        "    dataset_train,\n",
        "    validation_data = dataset_validation,\n",
        "    epochs = epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 54s 842ms/step - loss: 0.6911 - accuracy: 0.5295 - val_loss: 0.6692 - val_accuracy: 0.6101\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 53s 844ms/step - loss: 0.6598 - accuracy: 0.6115 - val_loss: 0.6372 - val_accuracy: 0.6671\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 54s 850ms/step - loss: 0.6175 - accuracy: 0.6640 - val_loss: 0.6177 - val_accuracy: 0.6844\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 54s 855ms/step - loss: 0.5835 - accuracy: 0.6950 - val_loss: 0.5928 - val_accuracy: 0.6757\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 54s 849ms/step - loss: 0.5465 - accuracy: 0.7390 - val_loss: 0.5832 - val_accuracy: 0.7067\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 53s 846ms/step - loss: 0.5191 - accuracy: 0.7565 - val_loss: 0.5653 - val_accuracy: 0.7042\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 53s 844ms/step - loss: 0.4962 - accuracy: 0.7665 - val_loss: 0.5627 - val_accuracy: 0.7079\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 53s 842ms/step - loss: 0.4909 - accuracy: 0.7625 - val_loss: 0.5551 - val_accuracy: 0.6931\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 53s 840ms/step - loss: 0.4531 - accuracy: 0.7970 - val_loss: 0.5433 - val_accuracy: 0.7339\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 53s 837ms/step - loss: 0.4438 - accuracy: 0.7980 - val_loss: 0.5552 - val_accuracy: 0.7104\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 52s 830ms/step - loss: 0.4245 - accuracy: 0.8100 - val_loss: 0.5777 - val_accuracy: 0.6894\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 52s 822ms/step - loss: 0.4024 - accuracy: 0.8230 - val_loss: 0.5310 - val_accuracy: 0.7339\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 53s 835ms/step - loss: 0.3855 - accuracy: 0.8435 - val_loss: 0.5571 - val_accuracy: 0.7079\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 53s 832ms/step - loss: 0.3735 - accuracy: 0.8385 - val_loss: 0.5710 - val_accuracy: 0.7104\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 52s 824ms/step - loss: 0.3637 - accuracy: 0.8420 - val_loss: 0.5592 - val_accuracy: 0.7129\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 53s 833ms/step - loss: 0.3345 - accuracy: 0.8705 - val_loss: 0.5410 - val_accuracy: 0.7376\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 52s 829ms/step - loss: 0.3071 - accuracy: 0.8705 - val_loss: 0.5596 - val_accuracy: 0.7277\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 52s 823ms/step - loss: 0.3012 - accuracy: 0.8700 - val_loss: 0.5558 - val_accuracy: 0.7302\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 52s 825ms/step - loss: 0.2742 - accuracy: 0.8985 - val_loss: 0.5702 - val_accuracy: 0.7351\n",
            "Epoch 20/20\n",
            "36/63 [================>.............] - ETA: 20s - loss: 0.2691 - accuracy: 0.8950"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OcNMS002yP4"
      },
      "source": [
        "def plot_model():\n",
        "\n",
        "  accuracy = history.history['accuracy'']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs_range = range(epochs)\n",
        "\n",
        "  plt.gcf().clear()\n",
        "  plt.figure(figsize = (15,8))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "  plt.plot(epochs_range, accuracy, label = 'Training Accuracy')\n",
        "  plt.plot(epochs_range, val_accuracy, label = 'Validation Accuracy')\n",
        "  plt.legend(loc = 'lower right')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.plot(epochs_range, loss, label = 'Training Loss')\n",
        "  plt.plot(epochs_range, val_loss, label = 'Validation Loss')\n",
        "  plt.legend(loc = 'lower right')\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOLGcULM4BoX"
      },
      "source": [
        "plot_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AGdQfSsxaiD"
      },
      "source": [
        "def plot_dataset_predictions(dataset):\n",
        "\n",
        "  features, labels = dataset.as_numpy_iterator().next()\n",
        "\n",
        "  predictions_aux = model.predict_on_batch(features).flatten()\n",
        "  predictions = tf.where(predictions_flatten <0.5, 0, 1)\n",
        "\n",
        "  print('Labels:      %s' % labels)\n",
        "  print('Predictions: %s' % predictions.numpy())\n",
        "\n",
        "  plt.gcf().clear()\n",
        "  plt.figure(figsize = (15,15))\n",
        "\n",
        "  for i in range(9):\n",
        "\n",
        "    plt.subplot(3,3, i + 1)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(features[i].astype('uint8'))\n",
        "    plt.title(class_names[predictions[i]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrW1Qc5xyzXL"
      },
      "source": [
        "plot_dataset_predictions(dataset_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJBXB9do2CPJ"
      },
      "source": [
        "# save model for production\n",
        "model.save('path/to/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyDRSyHx2hZI"
      },
      "source": [
        "# load saved model\n",
        "# model = tf.keras.load_model('path/to')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBwn8J7W2hTo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}